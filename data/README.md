The phoenix14T data is from "O. Koller, J. Forster, and H. Ney. Continuous sign language recognition: Towards large vocabulary statistical recognition systems handling multiple signers. Computer Vision and Image Understanding, volume 141, pages 108-125, December 2015."

The aslg data is from Achraf Othman and Zouhour Tmar. “English-ASL Gloss Parallel Corpus 2012: ASLG-PC12, The Second Release”. Fourth International Conference On Information and Communication Technology and Accessibility ICTA’13, Hammamet, Tunisia, October 24-26, 2013.

The stmc gloss data is from the "spatial-temporal multi-cue network for continuous sign language recognition, AAAI2020".
It's shared by Hao Zhou from the GIPAS lab in USTC, for non-commercial usage.
