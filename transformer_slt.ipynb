{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " transformer-slt.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNS4ywAm7wUGQBp1ylDGHSo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BDfriends/transformer-slt/blob/master/transformer_slt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxZRdI8m6Oeh",
        "outputId": "9f1828e0-dbe3-401b-eb9e-359249973430"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'transformer-slt'...\n",
            "remote: Enumerating objects: 270, done.\u001b[K\n",
            "remote: Counting objects: 100% (270/270), done.\u001b[K\n",
            "remote: Compressing objects: 100% (242/242), done.\u001b[K\n",
            "remote: Total 270 (delta 69), reused 203 (delta 24), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (270/270), 7.32 MiB | 6.32 MiB/s, done.\n",
            "Resolving deltas: 100% (69/69), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/BDfriends/transformer-slt.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd transformer-slt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IgKMHhz6del",
        "outputId": "7b00c3a2-a5cf-4ddd-eddb-8bc67fa83a44"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/transformer-slt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zokVi94-6iuL",
        "outputId": "9bc9d5e4-9c76-4e0e-ab85-049178ac1ade"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (3.7)\n",
            "Collecting torchtext==0.4\n",
            "  Downloading torchtext-0.4.0-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.8 MB/s \n",
            "\u001b[?25hCollecting tqdm~=4.30.0\n",
            "  Downloading tqdm-4.30.0-py2.py3-none-any.whl (47 kB)\n",
            "\u001b[K     |████████████████████████████████| 47 kB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4->-r requirements.txt (line 2)) (1.12.0+cu113)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4->-r requirements.txt (line 2)) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4->-r requirements.txt (line 2)) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4->-r requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk->-r requirements.txt (line 1)) (2022.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->-r requirements.txt (line 1)) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4->-r requirements.txt (line 2)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4->-r requirements.txt (line 2)) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4->-r requirements.txt (line 2)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4->-r requirements.txt (line 2)) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.4->-r requirements.txt (line 2)) (4.1.1)\n",
            "Installing collected packages: tqdm, torchtext\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.64.0\n",
            "    Uninstalling tqdm-4.64.0:\n",
            "      Successfully uninstalled tqdm-4.64.0\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.13.0\n",
            "    Uninstalling torchtext-0.13.0:\n",
            "      Successfully uninstalled torchtext-0.13.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 3.4.1 requires tqdm<5.0.0,>=4.38.0, but you have tqdm 4.30.0 which is incompatible.\n",
            "prophet 1.1 requires tqdm>=4.36.1, but you have tqdm 4.30.0 which is incompatible.\n",
            "panel 0.12.1 requires tqdm>=4.48.0, but you have tqdm 4.30.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torchtext-0.4.0 tqdm-4.30.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python setup.py install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnBk8IkZ6oml",
        "outputId": "6f3a9c69-1bb4-4b42-f1fe-ffa6bbd4b213"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating OpenNMT_py.egg-info\n",
            "writing OpenNMT_py.egg-info/PKG-INFO\n",
            "writing dependency_links to OpenNMT_py.egg-info/dependency_links.txt\n",
            "writing entry points to OpenNMT_py.egg-info/entry_points.txt\n",
            "writing requirements to OpenNMT_py.egg-info/requires.txt\n",
            "writing top-level names to OpenNMT_py.egg-info/top_level.txt\n",
            "writing manifest file 'OpenNMT_py.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE.md'\n",
            "writing manifest file 'OpenNMT_py.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/onmt\n",
            "copying onmt/opts.py -> build/lib/onmt\n",
            "copying onmt/train_single.py -> build/lib/onmt\n",
            "copying onmt/model_builder.py -> build/lib/onmt\n",
            "copying onmt/trainer.py -> build/lib/onmt\n",
            "copying onmt/__init__.py -> build/lib/onmt\n",
            "creating build/lib/onmt/bin\n",
            "copying onmt/bin/train.py -> build/lib/onmt/bin\n",
            "copying onmt/bin/average_models.py -> build/lib/onmt/bin\n",
            "copying onmt/bin/preprocess.py -> build/lib/onmt/bin\n",
            "copying onmt/bin/server.py -> build/lib/onmt/bin\n",
            "copying onmt/bin/release_model.py -> build/lib/onmt/bin\n",
            "copying onmt/bin/__init__.py -> build/lib/onmt/bin\n",
            "copying onmt/bin/translate.py -> build/lib/onmt/bin\n",
            "creating build/lib/onmt/decoders\n",
            "copying onmt/decoders/transformer.py -> build/lib/onmt/decoders\n",
            "copying onmt/decoders/ensemble.py -> build/lib/onmt/decoders\n",
            "copying onmt/decoders/decoder.py -> build/lib/onmt/decoders\n",
            "copying onmt/decoders/__init__.py -> build/lib/onmt/decoders\n",
            "creating build/lib/onmt/encoders\n",
            "copying onmt/encoders/transformer.py -> build/lib/onmt/encoders\n",
            "copying onmt/encoders/__init__.py -> build/lib/onmt/encoders\n",
            "copying onmt/encoders/rnn_encoder.py -> build/lib/onmt/encoders\n",
            "copying onmt/encoders/encoder.py -> build/lib/onmt/encoders\n",
            "copying onmt/encoders/mean_encoder.py -> build/lib/onmt/encoders\n",
            "creating build/lib/onmt/models\n",
            "copying onmt/models/stacked_rnn.py -> build/lib/onmt/models\n",
            "copying onmt/models/model.py -> build/lib/onmt/models\n",
            "copying onmt/models/sru.py -> build/lib/onmt/models\n",
            "copying onmt/models/model_saver.py -> build/lib/onmt/models\n",
            "copying onmt/models/__init__.py -> build/lib/onmt/models\n",
            "creating build/lib/onmt/modules\n",
            "copying onmt/modules/gate.py -> build/lib/onmt/modules\n",
            "copying onmt/modules/average_attn.py -> build/lib/onmt/modules\n",
            "copying onmt/modules/embeddings.py -> build/lib/onmt/modules\n",
            "copying onmt/modules/util_class.py -> build/lib/onmt/modules\n",
            "copying onmt/modules/copy_generator.py -> build/lib/onmt/modules\n",
            "copying onmt/modules/multi_headed_attn.py -> build/lib/onmt/modules\n",
            "copying onmt/modules/structured_attention.py -> build/lib/onmt/modules\n",
            "copying onmt/modules/global_attention.py -> build/lib/onmt/modules\n",
            "copying onmt/modules/position_ffn.py -> build/lib/onmt/modules\n",
            "copying onmt/modules/__init__.py -> build/lib/onmt/modules\n",
            "copying onmt/modules/conv_multi_step_attention.py -> build/lib/onmt/modules\n",
            "copying onmt/modules/sparse_losses.py -> build/lib/onmt/modules\n",
            "copying onmt/modules/weight_norm.py -> build/lib/onmt/modules\n",
            "copying onmt/modules/sparse_activations.py -> build/lib/onmt/modules\n",
            "creating build/lib/onmt/translate\n",
            "copying onmt/translate/translator.py -> build/lib/onmt/translate\n",
            "copying onmt/translate/process_zh.py -> build/lib/onmt/translate\n",
            "copying onmt/translate/translation.py -> build/lib/onmt/translate\n",
            "copying onmt/translate/decode_strategy.py -> build/lib/onmt/translate\n",
            "copying onmt/translate/greedy_search.py -> build/lib/onmt/translate\n",
            "copying onmt/translate/__init__.py -> build/lib/onmt/translate\n",
            "copying onmt/translate/translation_server.py -> build/lib/onmt/translate\n",
            "copying onmt/translate/penalties.py -> build/lib/onmt/translate\n",
            "copying onmt/translate/beam_search.py -> build/lib/onmt/translate\n",
            "creating build/lib/onmt/inputters\n",
            "copying onmt/inputters/text_dataset.py -> build/lib/onmt/inputters\n",
            "copying onmt/inputters/inputter.py -> build/lib/onmt/inputters\n",
            "copying onmt/inputters/dataset_base.py -> build/lib/onmt/inputters\n",
            "copying onmt/inputters/__init__.py -> build/lib/onmt/inputters\n",
            "copying onmt/inputters/datareader_base.py -> build/lib/onmt/inputters\n",
            "creating build/lib/onmt/utils\n",
            "copying onmt/utils/loss.py -> build/lib/onmt/utils\n",
            "copying onmt/utils/distributed.py -> build/lib/onmt/utils\n",
            "copying onmt/utils/parse.py -> build/lib/onmt/utils\n",
            "copying onmt/utils/rnn_factory.py -> build/lib/onmt/utils\n",
            "copying onmt/utils/alignment.py -> build/lib/onmt/utils\n",
            "copying onmt/utils/earlystopping.py -> build/lib/onmt/utils\n",
            "copying onmt/utils/optimizers.py -> build/lib/onmt/utils\n",
            "copying onmt/utils/report_manager.py -> build/lib/onmt/utils\n",
            "copying onmt/utils/logging.py -> build/lib/onmt/utils\n",
            "copying onmt/utils/__init__.py -> build/lib/onmt/utils\n",
            "copying onmt/utils/statistics.py -> build/lib/onmt/utils\n",
            "copying onmt/utils/misc.py -> build/lib/onmt/utils\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/onmt\n",
            "creating build/bdist.linux-x86_64/egg/onmt/bin\n",
            "copying build/lib/onmt/bin/train.py -> build/bdist.linux-x86_64/egg/onmt/bin\n",
            "copying build/lib/onmt/bin/average_models.py -> build/bdist.linux-x86_64/egg/onmt/bin\n",
            "copying build/lib/onmt/bin/preprocess.py -> build/bdist.linux-x86_64/egg/onmt/bin\n",
            "copying build/lib/onmt/bin/server.py -> build/bdist.linux-x86_64/egg/onmt/bin\n",
            "copying build/lib/onmt/bin/release_model.py -> build/bdist.linux-x86_64/egg/onmt/bin\n",
            "copying build/lib/onmt/bin/__init__.py -> build/bdist.linux-x86_64/egg/onmt/bin\n",
            "copying build/lib/onmt/bin/translate.py -> build/bdist.linux-x86_64/egg/onmt/bin\n",
            "copying build/lib/onmt/opts.py -> build/bdist.linux-x86_64/egg/onmt\n",
            "creating build/bdist.linux-x86_64/egg/onmt/decoders\n",
            "copying build/lib/onmt/decoders/transformer.py -> build/bdist.linux-x86_64/egg/onmt/decoders\n",
            "copying build/lib/onmt/decoders/ensemble.py -> build/bdist.linux-x86_64/egg/onmt/decoders\n",
            "copying build/lib/onmt/decoders/decoder.py -> build/bdist.linux-x86_64/egg/onmt/decoders\n",
            "copying build/lib/onmt/decoders/__init__.py -> build/bdist.linux-x86_64/egg/onmt/decoders\n",
            "creating build/bdist.linux-x86_64/egg/onmt/encoders\n",
            "copying build/lib/onmt/encoders/transformer.py -> build/bdist.linux-x86_64/egg/onmt/encoders\n",
            "copying build/lib/onmt/encoders/__init__.py -> build/bdist.linux-x86_64/egg/onmt/encoders\n",
            "copying build/lib/onmt/encoders/rnn_encoder.py -> build/bdist.linux-x86_64/egg/onmt/encoders\n",
            "copying build/lib/onmt/encoders/encoder.py -> build/bdist.linux-x86_64/egg/onmt/encoders\n",
            "copying build/lib/onmt/encoders/mean_encoder.py -> build/bdist.linux-x86_64/egg/onmt/encoders\n",
            "copying build/lib/onmt/train_single.py -> build/bdist.linux-x86_64/egg/onmt\n",
            "creating build/bdist.linux-x86_64/egg/onmt/models\n",
            "copying build/lib/onmt/models/stacked_rnn.py -> build/bdist.linux-x86_64/egg/onmt/models\n",
            "copying build/lib/onmt/models/model.py -> build/bdist.linux-x86_64/egg/onmt/models\n",
            "copying build/lib/onmt/models/sru.py -> build/bdist.linux-x86_64/egg/onmt/models\n",
            "copying build/lib/onmt/models/model_saver.py -> build/bdist.linux-x86_64/egg/onmt/models\n",
            "copying build/lib/onmt/models/__init__.py -> build/bdist.linux-x86_64/egg/onmt/models\n",
            "creating build/bdist.linux-x86_64/egg/onmt/modules\n",
            "copying build/lib/onmt/modules/gate.py -> build/bdist.linux-x86_64/egg/onmt/modules\n",
            "copying build/lib/onmt/modules/average_attn.py -> build/bdist.linux-x86_64/egg/onmt/modules\n",
            "copying build/lib/onmt/modules/embeddings.py -> build/bdist.linux-x86_64/egg/onmt/modules\n",
            "copying build/lib/onmt/modules/util_class.py -> build/bdist.linux-x86_64/egg/onmt/modules\n",
            "copying build/lib/onmt/modules/copy_generator.py -> build/bdist.linux-x86_64/egg/onmt/modules\n",
            "copying build/lib/onmt/modules/multi_headed_attn.py -> build/bdist.linux-x86_64/egg/onmt/modules\n",
            "copying build/lib/onmt/modules/structured_attention.py -> build/bdist.linux-x86_64/egg/onmt/modules\n",
            "copying build/lib/onmt/modules/global_attention.py -> build/bdist.linux-x86_64/egg/onmt/modules\n",
            "copying build/lib/onmt/modules/position_ffn.py -> build/bdist.linux-x86_64/egg/onmt/modules\n",
            "copying build/lib/onmt/modules/__init__.py -> build/bdist.linux-x86_64/egg/onmt/modules\n",
            "copying build/lib/onmt/modules/conv_multi_step_attention.py -> build/bdist.linux-x86_64/egg/onmt/modules\n",
            "copying build/lib/onmt/modules/sparse_losses.py -> build/bdist.linux-x86_64/egg/onmt/modules\n",
            "copying build/lib/onmt/modules/weight_norm.py -> build/bdist.linux-x86_64/egg/onmt/modules\n",
            "copying build/lib/onmt/modules/sparse_activations.py -> build/bdist.linux-x86_64/egg/onmt/modules\n",
            "copying build/lib/onmt/model_builder.py -> build/bdist.linux-x86_64/egg/onmt\n",
            "copying build/lib/onmt/trainer.py -> build/bdist.linux-x86_64/egg/onmt\n",
            "creating build/bdist.linux-x86_64/egg/onmt/translate\n",
            "copying build/lib/onmt/translate/translator.py -> build/bdist.linux-x86_64/egg/onmt/translate\n",
            "copying build/lib/onmt/translate/process_zh.py -> build/bdist.linux-x86_64/egg/onmt/translate\n",
            "copying build/lib/onmt/translate/translation.py -> build/bdist.linux-x86_64/egg/onmt/translate\n",
            "copying build/lib/onmt/translate/decode_strategy.py -> build/bdist.linux-x86_64/egg/onmt/translate\n",
            "copying build/lib/onmt/translate/greedy_search.py -> build/bdist.linux-x86_64/egg/onmt/translate\n",
            "copying build/lib/onmt/translate/__init__.py -> build/bdist.linux-x86_64/egg/onmt/translate\n",
            "copying build/lib/onmt/translate/translation_server.py -> build/bdist.linux-x86_64/egg/onmt/translate\n",
            "copying build/lib/onmt/translate/penalties.py -> build/bdist.linux-x86_64/egg/onmt/translate\n",
            "copying build/lib/onmt/translate/beam_search.py -> build/bdist.linux-x86_64/egg/onmt/translate\n",
            "copying build/lib/onmt/__init__.py -> build/bdist.linux-x86_64/egg/onmt\n",
            "creating build/bdist.linux-x86_64/egg/onmt/inputters\n",
            "copying build/lib/onmt/inputters/text_dataset.py -> build/bdist.linux-x86_64/egg/onmt/inputters\n",
            "copying build/lib/onmt/inputters/inputter.py -> build/bdist.linux-x86_64/egg/onmt/inputters\n",
            "copying build/lib/onmt/inputters/dataset_base.py -> build/bdist.linux-x86_64/egg/onmt/inputters\n",
            "copying build/lib/onmt/inputters/__init__.py -> build/bdist.linux-x86_64/egg/onmt/inputters\n",
            "copying build/lib/onmt/inputters/datareader_base.py -> build/bdist.linux-x86_64/egg/onmt/inputters\n",
            "creating build/bdist.linux-x86_64/egg/onmt/utils\n",
            "copying build/lib/onmt/utils/loss.py -> build/bdist.linux-x86_64/egg/onmt/utils\n",
            "copying build/lib/onmt/utils/distributed.py -> build/bdist.linux-x86_64/egg/onmt/utils\n",
            "copying build/lib/onmt/utils/parse.py -> build/bdist.linux-x86_64/egg/onmt/utils\n",
            "copying build/lib/onmt/utils/rnn_factory.py -> build/bdist.linux-x86_64/egg/onmt/utils\n",
            "copying build/lib/onmt/utils/alignment.py -> build/bdist.linux-x86_64/egg/onmt/utils\n",
            "copying build/lib/onmt/utils/earlystopping.py -> build/bdist.linux-x86_64/egg/onmt/utils\n",
            "copying build/lib/onmt/utils/optimizers.py -> build/bdist.linux-x86_64/egg/onmt/utils\n",
            "copying build/lib/onmt/utils/report_manager.py -> build/bdist.linux-x86_64/egg/onmt/utils\n",
            "copying build/lib/onmt/utils/logging.py -> build/bdist.linux-x86_64/egg/onmt/utils\n",
            "copying build/lib/onmt/utils/__init__.py -> build/bdist.linux-x86_64/egg/onmt/utils\n",
            "copying build/lib/onmt/utils/statistics.py -> build/bdist.linux-x86_64/egg/onmt/utils\n",
            "copying build/lib/onmt/utils/misc.py -> build/bdist.linux-x86_64/egg/onmt/utils\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/bin/train.py to train.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/bin/average_models.py to average_models.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/bin/preprocess.py to preprocess.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/bin/server.py to server.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/bin/release_model.py to release_model.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/bin/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/bin/translate.py to translate.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/opts.py to opts.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/decoders/transformer.py to transformer.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/decoders/ensemble.py to ensemble.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/decoders/decoder.py to decoder.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/decoders/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/encoders/transformer.py to transformer.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/encoders/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/encoders/rnn_encoder.py to rnn_encoder.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/encoders/encoder.py to encoder.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/encoders/mean_encoder.py to mean_encoder.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/train_single.py to train_single.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/models/stacked_rnn.py to stacked_rnn.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/models/model.py to model.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/models/sru.py to sru.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/models/model_saver.py to model_saver.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/models/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/modules/gate.py to gate.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/modules/average_attn.py to average_attn.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/modules/embeddings.py to embeddings.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/modules/util_class.py to util_class.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/modules/copy_generator.py to copy_generator.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/modules/multi_headed_attn.py to multi_headed_attn.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/modules/structured_attention.py to structured_attention.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/modules/global_attention.py to global_attention.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/modules/position_ffn.py to position_ffn.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/modules/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/modules/conv_multi_step_attention.py to conv_multi_step_attention.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/modules/sparse_losses.py to sparse_losses.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/modules/weight_norm.py to weight_norm.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/modules/sparse_activations.py to sparse_activations.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/model_builder.py to model_builder.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/trainer.py to trainer.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/translate/translator.py to translator.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/translate/process_zh.py to process_zh.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/translate/translation.py to translation.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/translate/decode_strategy.py to decode_strategy.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/translate/greedy_search.py to greedy_search.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/translate/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/translate/translation_server.py to translation_server.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/translate/penalties.py to penalties.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/translate/beam_search.py to beam_search.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/inputters/text_dataset.py to text_dataset.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/inputters/inputter.py to inputter.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/inputters/dataset_base.py to dataset_base.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/inputters/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/inputters/datareader_base.py to datareader_base.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/utils/loss.py to loss.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/utils/distributed.py to distributed.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/utils/parse.py to parse.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/utils/rnn_factory.py to rnn_factory.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/utils/alignment.py to alignment.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/utils/earlystopping.py to earlystopping.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/utils/optimizers.py to optimizers.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/utils/report_manager.py to report_manager.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/utils/logging.py to logging.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/utils/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/utils/statistics.py to statistics.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/onmt/utils/misc.py to misc.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying OpenNMT_py.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying OpenNMT_py.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying OpenNMT_py.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying OpenNMT_py.egg-info/entry_points.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying OpenNMT_py.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying OpenNMT_py.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/OpenNMT_py-1.0.0-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing OpenNMT_py-1.0.0-py3.7.egg\n",
            "Copying OpenNMT_py-1.0.0-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n",
            "Adding OpenNMT-py 1.0.0 to easy-install.pth file\n",
            "Installing onmt_average_models script to /usr/local/bin\n",
            "Installing onmt_preprocess script to /usr/local/bin\n",
            "Installing onmt_release_model script to /usr/local/bin\n",
            "Installing onmt_server script to /usr/local/bin\n",
            "Installing onmt_train script to /usr/local/bin\n",
            "Installing onmt_translate script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/OpenNMT_py-1.0.0-py3.7.egg\n",
            "Processing dependencies for OpenNMT-py==1.0.0\n",
            "Searching for pyonmttok==1.*\n",
            "Reading https://pypi.org/simple/pyonmttok/\n",
            "Downloading https://files.pythonhosted.org/packages/5e/c9/78b1d23574235c053a665c9d7e3d76d0bfa8af0624a6a356b6796eccd13e/pyonmttok-1.32.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl#sha256=09aa0154bd6f66558384065294d88e26c0236aa5629d157b23dbf3e16c359ddf\n",
            "Best match: pyonmttok 1.32.0\n",
            "Processing pyonmttok-1.32.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n",
            "Installing pyonmttok-1.32.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl to /usr/local/lib/python3.7/dist-packages\n",
            "Adding pyonmttok 1.32.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/pyonmttok-1.32.0-py3.7-linux-x86_64.egg\n",
            "Searching for waitress\n",
            "Reading https://pypi.org/simple/waitress/\n",
            "Downloading https://files.pythonhosted.org/packages/58/6a/b4b5c582e04e837e4422cab6ec9de7fc10ca7ad7f4e370bb89d280d39552/waitress-2.1.2-py3-none-any.whl#sha256=7500c9625927c8ec60f54377d590f67b30c8e70ef4b8894214ac6e4cad233d2a\n",
            "Best match: waitress 2.1.2\n",
            "Processing waitress-2.1.2-py3-none-any.whl\n",
            "Installing waitress-2.1.2-py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
            "Adding waitress 2.1.2 to easy-install.pth file\n",
            "Installing waitress-serve script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/waitress-2.1.2-py3.7.egg\n",
            "Searching for configargparse\n",
            "Reading https://pypi.org/simple/configargparse/\n",
            "Downloading https://files.pythonhosted.org/packages/af/cb/2a6620656f029b7b49c302853b433fac2c8eda9cbb5a3bc70b186b1b5b90/ConfigArgParse-1.5.3-py3-none-any.whl#sha256=18f6535a2db9f6e02bd5626cc7455eac3e96b9ab3d969d366f9aafd5c5c00fe7\n",
            "Best match: ConfigArgParse 1.5.3\n",
            "Processing ConfigArgParse-1.5.3-py3-none-any.whl\n",
            "Installing ConfigArgParse-1.5.3-py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n",
            "Adding ConfigArgParse 1.5.3 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/ConfigArgParse-1.5.3-py3.7.egg\n",
            "Searching for Flask==1.1.4\n",
            "Best match: Flask 1.1.4\n",
            "Adding Flask 1.1.4 to easy-install.pth file\n",
            "Installing flask script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tensorboard==2.8.0\n",
            "Best match: tensorboard 2.8.0\n",
            "Adding tensorboard 2.8.0 to easy-install.pth file\n",
            "Installing tensorboard script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for future==0.16.0\n",
            "Best match: future 0.16.0\n",
            "Adding future 0.16.0 to easy-install.pth file\n",
            "Installing futurize script to /usr/local/bin\n",
            "Installing pasteurize script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for torchtext==0.4.0\n",
            "Best match: torchtext 0.4.0\n",
            "Adding torchtext 0.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for torch==1.12.0+cu113\n",
            "Best match: torch 1.12.0+cu113\n",
            "Adding torch 1.12.0+cu113 to easy-install.pth file\n",
            "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
            "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
            "Installing torchrun script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tqdm==4.30.0\n",
            "Best match: tqdm 4.30.0\n",
            "Adding tqdm 4.30.0 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for six==1.15.0\n",
            "Best match: six 1.15.0\n",
            "Adding six 1.15.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for click==7.1.2\n",
            "Best match: click 7.1.2\n",
            "Adding click 7.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for itsdangerous==1.1.0\n",
            "Best match: itsdangerous 1.1.0\n",
            "Adding itsdangerous 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Werkzeug==1.0.1\n",
            "Best match: Werkzeug 1.0.1\n",
            "Adding Werkzeug 1.0.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Jinja2==2.11.3\n",
            "Best match: Jinja2 2.11.3\n",
            "Adding Jinja2 2.11.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Markdown==3.4.1\n",
            "Best match: Markdown 3.4.1\n",
            "Adding Markdown 3.4.1 to easy-install.pth file\n",
            "Installing markdown_py script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for wheel==0.37.1\n",
            "Best match: wheel 0.37.1\n",
            "Adding wheel 0.37.1 to easy-install.pth file\n",
            "Installing wheel script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for google-auth==1.35.0\n",
            "Best match: google-auth 1.35.0\n",
            "Adding google-auth 1.35.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for protobuf==3.17.3\n",
            "Best match: protobuf 3.17.3\n",
            "Adding protobuf 3.17.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for grpcio==1.47.0\n",
            "Best match: grpcio 1.47.0\n",
            "Adding grpcio 1.47.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for setuptools==57.4.0\n",
            "Best match: setuptools 57.4.0\n",
            "Adding setuptools 57.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tensorboard-plugin-wit==1.8.1\n",
            "Best match: tensorboard-plugin-wit 1.8.1\n",
            "Adding tensorboard-plugin-wit 1.8.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for google-auth-oauthlib==0.4.6\n",
            "Best match: google-auth-oauthlib 0.4.6\n",
            "Adding google-auth-oauthlib 0.4.6 to easy-install.pth file\n",
            "Installing google-oauthlib-tool script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for numpy==1.21.6\n",
            "Best match: numpy 1.21.6\n",
            "Adding numpy 1.21.6 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.7 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tensorboard-data-server==0.6.1\n",
            "Best match: tensorboard-data-server 0.6.1\n",
            "Adding tensorboard-data-server 0.6.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for requests==2.23.0\n",
            "Best match: requests 2.23.0\n",
            "Adding requests 2.23.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for absl-py==1.2.0\n",
            "Best match: absl-py 1.2.0\n",
            "Adding absl-py 1.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for typing-extensions==4.1.1\n",
            "Best match: typing-extensions 4.1.1\n",
            "Adding typing-extensions 4.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for MarkupSafe==2.0.1\n",
            "Best match: MarkupSafe 2.0.1\n",
            "Adding MarkupSafe 2.0.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for importlib-metadata==4.12.0\n",
            "Best match: importlib-metadata 4.12.0\n",
            "Adding importlib-metadata 4.12.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for cachetools==4.2.4\n",
            "Best match: cachetools 4.2.4\n",
            "Adding cachetools 4.2.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for rsa==4.9\n",
            "Best match: rsa 4.9\n",
            "Adding rsa 4.9 to easy-install.pth file\n",
            "Installing pyrsa-decrypt script to /usr/local/bin\n",
            "Installing pyrsa-encrypt script to /usr/local/bin\n",
            "Installing pyrsa-keygen script to /usr/local/bin\n",
            "Installing pyrsa-priv2pub script to /usr/local/bin\n",
            "Installing pyrsa-sign script to /usr/local/bin\n",
            "Installing pyrsa-verify script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pyasn1-modules==0.2.8\n",
            "Best match: pyasn1-modules 0.2.8\n",
            "Adding pyasn1-modules 0.2.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for requests-oauthlib==1.3.1\n",
            "Best match: requests-oauthlib 1.3.1\n",
            "Adding requests-oauthlib 1.3.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for urllib3==1.24.3\n",
            "Best match: urllib3 1.24.3\n",
            "Adding urllib3 1.24.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for chardet==3.0.4\n",
            "Best match: chardet 3.0.4\n",
            "Adding chardet 3.0.4 to easy-install.pth file\n",
            "Installing chardetect script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for certifi==2022.6.15\n",
            "Best match: certifi 2022.6.15\n",
            "Adding certifi 2022.6.15 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for idna==2.10\n",
            "Best match: idna 2.10\n",
            "Adding idna 2.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for zipp==3.8.1\n",
            "Best match: zipp 3.8.1\n",
            "Adding zipp 3.8.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pyasn1==0.4.8\n",
            "Best match: pyasn1 0.4.8\n",
            "Adding pyasn1 0.4.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for oauthlib==3.2.0\n",
            "Best match: oauthlib 3.2.0\n",
            "Adding oauthlib 3.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Finished processing dependencies for OpenNMT-py==1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!onmt_preprocess -train_src data/phoenix2014T.train.gloss -train_tgt data/phoenix2014T.train.de -valid_src data/phoenix2014T.dev.gloss -valid_tgt data/phoenix2014T.dev.de -save_data data/dgs -lower "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nULd_4mb6wKC",
        "outputId": "97861acb-4d4e-470f-88b8-4166231d08f1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2022-07-30 07:56:01,508 INFO] Extracting features...\n",
            "[2022-07-30 07:56:01,508 INFO]  * number of source features: 0.\n",
            "[2022-07-30 07:56:01,508 INFO]  * number of target features: 0.\n",
            "[2022-07-30 07:56:01,508 INFO] Building `Fields` object...\n",
            "[2022-07-30 07:56:01,508 INFO] Building & saving training data...\n",
            "[2022-07-30 07:56:01,528 INFO] Building shard 0.\n",
            "[2022-07-30 07:56:01,738 INFO]  * saving 0th train data shard to data/dgs.train.0.pt.\n",
            "[2022-07-30 07:56:02,023 INFO]  * tgt vocab size: 2889.\n",
            "[2022-07-30 07:56:02,025 INFO]  * src vocab size: 1233.\n",
            "[2022-07-30 07:56:02,035 INFO] Building & saving validation data...\n",
            "[2022-07-30 07:56:02,047 INFO] Building shard 0.\n",
            "[2022-07-30 07:56:02,054 INFO]  * saving 0th valid data shard to data/dgs.valid.0.pt.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python  train.py -data data/dgs -save_model model -keep_checkpoint 1 \\\n",
        "          -layers 2 -rnn_size 512 -word_vec_size 512 -transformer_ff 2048 -heads 8  \\\n",
        "          -encoder_type transformer -decoder_type transformer -position_encoding \\\n",
        "          -max_generator_batches 2 -dropout 0.1 \\\n",
        "          -early_stopping 3 -early_stopping_criteria accuracy ppl \\\n",
        "          -batch_size 2048 -accum_count 3 -batch_type tokens -normalization tokens \\\n",
        "          -optim adam -adam_beta2 0.998 -decay_method noam -warmup_steps 3000 -learning_rate 0.5 \\\n",
        "          -max_grad_norm 0 -param_init 0  -param_init_glorot \\\n",
        "          -label_smoothing 0.1 -valid_steps 100 -save_checkpoint_steps 100 \\\n",
        "          -world_size 1 -gpu_ranks 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypZ01wwn8dfh",
        "outputId": "867e2f30-b767-46a9-ec50-be649bbee202"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2022-07-30 07:56:10,195 INFO]  * src vocab size = 1233\n",
            "[2022-07-30 07:56:10,195 INFO]  * tgt vocab size = 2889\n",
            "[2022-07-30 07:56:10,195 INFO] Building model...\n",
            "[2022-07-30 07:56:14,320 INFO] NMTModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(1233, 512, padding_idx=1)\n",
            "        )\n",
            "        (pe): PositionalEncoding(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (transformer): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(2889, 512, padding_idx=1)\n",
            "        )\n",
            "        (pe): PositionalEncoding(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (transformer_layers): ModuleList(\n",
            "      (0): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (1): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "  )\n",
            "  (generator): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=2889, bias=True)\n",
            "    (1): Cast()\n",
            "    (2): LogSoftmax(dim=-1)\n",
            "  )\n",
            ")\n",
            "[2022-07-30 07:56:14,321 INFO] encoder: 6937088\n",
            "[2022-07-30 07:56:14,322 INFO] decoder: 11370313\n",
            "[2022-07-30 07:56:14,322 INFO] * number of parameters: 18307401\n",
            "[2022-07-30 07:56:14,323 INFO] Starting training on GPU: [0]\n",
            "[2022-07-30 07:56:14,323 INFO] Start training loop and validate every 100 steps...\n",
            "[2022-07-30 07:56:14,324 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:56:14,433 INFO] number of examples: 7095\n",
            "[2022-07-30 07:56:20,946 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:56:21,105 INFO] number of examples: 7095\n",
            "[2022-07-30 07:56:25,382 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:56:25,487 INFO] number of examples: 7095\n",
            "[2022-07-30 07:56:26,224 INFO] Step 50/100000; acc:   2.10; ppl: 845.38; xent: 6.74; lr: 0.00001; 12344/20750 tok/s;     12 sec\n",
            "[2022-07-30 07:56:29,726 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:56:29,879 INFO] number of examples: 7095\n",
            "[2022-07-30 07:56:34,131 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:56:34,292 INFO] number of examples: 7095\n",
            "[2022-07-30 07:56:35,803 INFO] Step 100/100000; acc:   9.51; ppl: 384.92; xent: 5.95; lr: 0.00001; 15483/25769 tok/s;     21 sec\n",
            "[2022-07-30 07:56:35,803 INFO] Loading dataset from data/dgs.valid.0.pt\n",
            "[2022-07-30 07:56:35,810 INFO] number of examples: 519\n",
            "[2022-07-30 07:56:35,983 INFO] Validation perplexity: 636.491\n",
            "[2022-07-30 07:56:35,983 INFO] Validation accuracy: 12.1278\n",
            "[2022-07-30 07:56:35,983 INFO] Model is improving ppl: inf --> 636.491.\n",
            "[2022-07-30 07:56:35,984 INFO] Model is improving acc: -inf --> 12.1278.\n",
            "[2022-07-30 07:56:35,995 INFO] Saving checkpoint model_step_100.pt\n",
            "[2022-07-30 07:56:39,243 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:56:39,354 INFO] number of examples: 7095\n",
            "[2022-07-30 07:56:43,659 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:56:43,815 INFO] number of examples: 7095\n",
            "[2022-07-30 07:56:46,065 INFO] Step 150/100000; acc:  12.04; ppl: 219.32; xent: 5.39; lr: 0.00002; 14148/23759 tok/s;     32 sec\n",
            "[2022-07-30 07:56:48,146 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:56:48,253 INFO] number of examples: 7095\n",
            "[2022-07-30 07:56:52,667 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:56:52,774 INFO] number of examples: 7095\n",
            "[2022-07-30 07:56:55,815 INFO] Step 200/100000; acc:  14.48; ppl: 136.11; xent: 4.91; lr: 0.00003; 15174/25359 tok/s;     41 sec\n",
            "[2022-07-30 07:56:55,815 INFO] Loading dataset from data/dgs.valid.0.pt\n",
            "[2022-07-30 07:56:55,822 INFO] number of examples: 519\n",
            "[2022-07-30 07:56:55,997 INFO] Validation perplexity: 214.196\n",
            "[2022-07-30 07:56:55,998 INFO] Validation accuracy: 16.1237\n",
            "[2022-07-30 07:56:55,998 INFO] Model is improving ppl: 636.491 --> 214.196.\n",
            "[2022-07-30 07:56:55,998 INFO] Model is improving acc: 12.1278 --> 16.1237.\n",
            "[2022-07-30 07:56:56,009 INFO] Saving checkpoint model_step_200.pt\n",
            "[2022-07-30 07:56:57,938 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:56:58,223 INFO] number of examples: 7095\n",
            "[2022-07-30 07:57:02,700 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:57:02,806 INFO] number of examples: 7095\n",
            "[2022-07-30 07:57:06,644 INFO] Step 250/100000; acc:  17.90; ppl: 93.57; xent: 4.54; lr: 0.00003; 13603/22707 tok/s;     52 sec\n",
            "[2022-07-30 07:57:07,231 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:57:07,390 INFO] number of examples: 7095\n",
            "[2022-07-30 07:57:11,858 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:57:11,966 INFO] number of examples: 7095\n",
            "[2022-07-30 07:57:16,523 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:57:16,630 INFO] number of examples: 7095\n",
            "[2022-07-30 07:57:16,832 INFO] Step 300/100000; acc:  23.24; ppl: 65.82; xent: 4.19; lr: 0.00004; 14486/24166 tok/s;     63 sec\n",
            "[2022-07-30 07:57:16,833 INFO] Loading dataset from data/dgs.valid.0.pt\n",
            "[2022-07-30 07:57:16,841 INFO] number of examples: 519\n",
            "[2022-07-30 07:57:17,018 INFO] Validation perplexity: 90.5212\n",
            "[2022-07-30 07:57:17,018 INFO] Validation accuracy: 26.5971\n",
            "[2022-07-30 07:57:17,018 INFO] Model is improving ppl: 214.196 --> 90.5212.\n",
            "[2022-07-30 07:57:17,018 INFO] Model is improving acc: 16.1237 --> 26.5971.\n",
            "[2022-07-30 07:57:17,029 INFO] Saving checkpoint model_step_300.pt\n",
            "[2022-07-30 07:57:21,878 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:57:22,038 INFO] number of examples: 7095\n",
            "[2022-07-30 07:57:26,580 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:57:26,686 INFO] number of examples: 7095\n",
            "[2022-07-30 07:57:27,689 INFO] Step 350/100000; acc:  27.24; ppl: 46.97; xent: 3.85; lr: 0.00005; 13595/22727 tok/s;     73 sec\n",
            "[2022-07-30 07:57:31,269 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:57:31,428 INFO] number of examples: 7095\n",
            "[2022-07-30 07:57:36,030 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:57:36,150 INFO] number of examples: 7095\n",
            "[2022-07-30 07:57:38,017 INFO] Step 400/100000; acc:  30.89; ppl: 35.38; xent: 3.57; lr: 0.00005; 14304/23847 tok/s;     84 sec\n",
            "[2022-07-30 07:57:38,017 INFO] Loading dataset from data/dgs.valid.0.pt\n",
            "[2022-07-30 07:57:38,026 INFO] number of examples: 519\n",
            "[2022-07-30 07:57:38,213 INFO] Validation perplexity: 45.0275\n",
            "[2022-07-30 07:57:38,213 INFO] Validation accuracy: 35.1616\n",
            "[2022-07-30 07:57:38,213 INFO] Model is improving ppl: 90.5212 --> 45.0275.\n",
            "[2022-07-30 07:57:38,213 INFO] Model is improving acc: 26.5971 --> 35.1616.\n",
            "[2022-07-30 07:57:38,227 INFO] Saving checkpoint model_step_400.pt\n",
            "[2022-07-30 07:57:41,509 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:57:41,617 INFO] number of examples: 7095\n",
            "[2022-07-30 07:57:46,196 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:57:46,363 INFO] number of examples: 7095\n",
            "[2022-07-30 07:57:48,938 INFO] Step 450/100000; acc:  34.60; ppl: 27.05; xent: 3.30; lr: 0.00006; 13312/22370 tok/s;     95 sec\n",
            "[2022-07-30 07:57:50,925 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:57:51,036 INFO] number of examples: 7095\n",
            "[2022-07-30 07:57:55,579 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:57:55,741 INFO] number of examples: 7095\n",
            "[2022-07-30 07:57:59,078 INFO] Step 500/100000; acc:  37.87; ppl: 21.53; xent: 3.07; lr: 0.00007; 14596/24385 tok/s;    105 sec\n",
            "[2022-07-30 07:57:59,079 INFO] Loading dataset from data/dgs.valid.0.pt\n",
            "[2022-07-30 07:57:59,086 INFO] number of examples: 519\n",
            "[2022-07-30 07:57:59,267 INFO] Validation perplexity: 27.999\n",
            "[2022-07-30 07:57:59,267 INFO] Validation accuracy: 40.8374\n",
            "[2022-07-30 07:57:59,268 INFO] Model is improving ppl: 45.0275 --> 27.999.\n",
            "[2022-07-30 07:57:59,268 INFO] Model is improving acc: 35.1616 --> 40.8374.\n",
            "[2022-07-30 07:57:59,280 INFO] Saving checkpoint model_step_500.pt\n",
            "[2022-07-30 07:58:00,959 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:58:01,128 INFO] number of examples: 7095\n",
            "[2022-07-30 07:58:05,619 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:58:05,736 INFO] number of examples: 7095\n",
            "[2022-07-30 07:58:09,825 INFO] Step 550/100000; acc:  40.97; ppl: 17.48; xent: 2.86; lr: 0.00007; 13672/22802 tok/s;    116 sec\n",
            "[2022-07-30 07:58:10,230 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:58:10,389 INFO] number of examples: 7095\n",
            "[2022-07-30 07:58:14,862 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:58:14,971 INFO] number of examples: 7095\n",
            "[2022-07-30 07:58:19,445 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:58:19,607 INFO] number of examples: 7095\n",
            "[2022-07-30 07:58:20,008 INFO] Step 600/100000; acc:  43.62; ppl: 14.44; xent: 2.67; lr: 0.00008; 14559/24305 tok/s;    126 sec\n",
            "[2022-07-30 07:58:20,009 INFO] Loading dataset from data/dgs.valid.0.pt\n",
            "[2022-07-30 07:58:20,016 INFO] number of examples: 519\n",
            "[2022-07-30 07:58:20,195 INFO] Validation perplexity: 19.8016\n",
            "[2022-07-30 07:58:20,195 INFO] Validation accuracy: 45.0369\n",
            "[2022-07-30 07:58:20,195 INFO] Model is improving ppl: 27.999 --> 19.8016.\n",
            "[2022-07-30 07:58:20,195 INFO] Model is improving acc: 40.8374 --> 45.0369.\n",
            "[2022-07-30 07:58:20,206 INFO] Saving checkpoint model_step_600.pt\n",
            "[2022-07-30 07:58:24,840 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:58:25,148 INFO] number of examples: 7095\n",
            "[2022-07-30 07:58:29,658 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:58:29,766 INFO] number of examples: 7095\n",
            "[2022-07-30 07:58:30,947 INFO] Step 650/100000; acc:  45.91; ppl: 12.30; xent: 2.51; lr: 0.00009; 13516/22540 tok/s;    137 sec\n",
            "[2022-07-30 07:58:34,256 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:58:34,424 INFO] number of examples: 7095\n",
            "[2022-07-30 07:58:38,900 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:58:39,008 INFO] number of examples: 7095\n",
            "[2022-07-30 07:58:40,984 INFO] Step 700/100000; acc:  48.16; ppl: 10.69; xent: 2.37; lr: 0.00009; 14669/24543 tok/s;    147 sec\n",
            "[2022-07-30 07:58:40,985 INFO] Loading dataset from data/dgs.valid.0.pt\n",
            "[2022-07-30 07:58:40,992 INFO] number of examples: 519\n",
            "[2022-07-30 07:58:41,170 INFO] Validation perplexity: 15.2036\n",
            "[2022-07-30 07:58:41,170 INFO] Validation accuracy: 48.7529\n",
            "[2022-07-30 07:58:41,170 INFO] Model is improving ppl: 19.8016 --> 15.2036.\n",
            "[2022-07-30 07:58:41,170 INFO] Model is improving acc: 45.0369 --> 48.7529.\n",
            "[2022-07-30 07:58:41,182 INFO] Saving checkpoint model_step_700.pt\n",
            "[2022-07-30 07:58:44,203 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:58:44,357 INFO] number of examples: 7095\n",
            "[2022-07-30 07:58:48,858 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:58:49,031 INFO] number of examples: 7095\n",
            "[2022-07-30 07:58:51,753 INFO] Step 750/100000; acc:  50.75; ppl:  9.15; xent: 2.21; lr: 0.00010; 13540/22721 tok/s;    157 sec\n",
            "[2022-07-30 07:58:53,535 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:58:53,651 INFO] number of examples: 7095\n",
            "[2022-07-30 07:58:58,157 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:58:58,313 INFO] number of examples: 7095\n",
            "[2022-07-30 07:59:01,840 INFO] Step 800/100000; acc:  52.57; ppl:  8.13; xent: 2.10; lr: 0.00011; 14646/24432 tok/s;    168 sec\n",
            "[2022-07-30 07:59:01,840 INFO] Loading dataset from data/dgs.valid.0.pt\n",
            "[2022-07-30 07:59:01,848 INFO] number of examples: 519\n",
            "[2022-07-30 07:59:02,022 INFO] Validation perplexity: 12.7816\n",
            "[2022-07-30 07:59:02,022 INFO] Validation accuracy: 50.9799\n",
            "[2022-07-30 07:59:02,023 INFO] Model is improving ppl: 15.2036 --> 12.7816.\n",
            "[2022-07-30 07:59:02,023 INFO] Model is improving acc: 48.7529 --> 50.9799.\n",
            "[2022-07-30 07:59:02,034 INFO] Saving checkpoint model_step_800.pt\n",
            "[2022-07-30 07:59:03,531 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:59:03,639 INFO] number of examples: 7095\n",
            "[2022-07-30 07:59:08,216 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:59:08,325 INFO] number of examples: 7095\n",
            "[2022-07-30 07:59:12,654 INFO] Step 850/100000; acc:  54.84; ppl:  7.11; xent: 1.96; lr: 0.00011; 13579/22680 tok/s;    178 sec\n",
            "[2022-07-30 07:59:12,861 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:59:13,035 INFO] number of examples: 7095\n",
            "[2022-07-30 07:59:17,560 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:59:17,670 INFO] number of examples: 7095\n",
            "[2022-07-30 07:59:22,200 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:59:22,361 INFO] number of examples: 7095\n",
            "[2022-07-30 07:59:22,957 INFO] Step 900/100000; acc:  56.80; ppl:  6.41; xent: 1.86; lr: 0.00012; 14404/24064 tok/s;    189 sec\n",
            "[2022-07-30 07:59:22,958 INFO] Loading dataset from data/dgs.valid.0.pt\n",
            "[2022-07-30 07:59:22,965 INFO] number of examples: 519\n",
            "[2022-07-30 07:59:23,144 INFO] Validation perplexity: 11.3641\n",
            "[2022-07-30 07:59:23,144 INFO] Validation accuracy: 52.927\n",
            "[2022-07-30 07:59:23,144 INFO] Model is improving ppl: 12.7816 --> 11.3641.\n",
            "[2022-07-30 07:59:23,144 INFO] Model is improving acc: 50.9799 --> 52.927.\n",
            "[2022-07-30 07:59:23,156 INFO] Saving checkpoint model_step_900.pt\n",
            "[2022-07-30 07:59:27,550 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:59:27,658 INFO] number of examples: 7095\n",
            "[2022-07-30 07:59:32,233 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:59:32,342 INFO] number of examples: 7095\n",
            "[2022-07-30 07:59:33,714 INFO] Step 950/100000; acc:  58.79; ppl:  5.73; xent: 1.75; lr: 0.00013; 13735/22941 tok/s;    199 sec\n",
            "[2022-07-30 07:59:36,845 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:59:37,008 INFO] number of examples: 7095\n",
            "[2022-07-30 07:59:41,522 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:59:41,631 INFO] number of examples: 7095\n",
            "[2022-07-30 07:59:43,785 INFO] Step 1000/100000; acc:  60.09; ppl:  5.31; xent: 1.67; lr: 0.00013; 14504/24279 tok/s;    209 sec\n",
            "[2022-07-30 07:59:43,786 INFO] Loading dataset from data/dgs.valid.0.pt\n",
            "[2022-07-30 07:59:43,794 INFO] number of examples: 519\n",
            "[2022-07-30 07:59:43,969 INFO] Validation perplexity: 10.6779\n",
            "[2022-07-30 07:59:43,969 INFO] Validation accuracy: 53.9578\n",
            "[2022-07-30 07:59:43,969 INFO] Model is improving ppl: 11.3641 --> 10.6779.\n",
            "[2022-07-30 07:59:43,969 INFO] Model is improving acc: 52.927 --> 53.9578.\n",
            "[2022-07-30 07:59:43,980 INFO] Saving checkpoint model_step_1000.pt\n",
            "[2022-07-30 07:59:46,846 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:59:47,004 INFO] number of examples: 7095\n",
            "[2022-07-30 07:59:51,558 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:59:51,781 INFO] number of examples: 7095\n",
            "[2022-07-30 07:59:54,795 INFO] Step 1050/100000; acc:  62.41; ppl:  4.72; xent: 1.55; lr: 0.00014; 13339/22330 tok/s;    220 sec\n",
            "[2022-07-30 07:59:56,369 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 07:59:56,481 INFO] number of examples: 7095\n",
            "[2022-07-30 08:00:00,973 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 08:00:01,134 INFO] number of examples: 7095\n",
            "[2022-07-30 08:00:04,826 INFO] Step 1100/100000; acc:  63.99; ppl:  4.34; xent: 1.47; lr: 0.00015; 14649/24506 tok/s;    231 sec\n",
            "[2022-07-30 08:00:04,827 INFO] Loading dataset from data/dgs.valid.0.pt\n",
            "[2022-07-30 08:00:04,836 INFO] number of examples: 519\n",
            "[2022-07-30 08:00:04,999 INFO] Validation perplexity: 10.0899\n",
            "[2022-07-30 08:00:05,000 INFO] Validation accuracy: 54.7977\n",
            "[2022-07-30 08:00:05,000 INFO] Model is improving ppl: 10.6779 --> 10.0899.\n",
            "[2022-07-30 08:00:05,000 INFO] Model is improving acc: 53.9578 --> 54.7977.\n",
            "[2022-07-30 08:00:05,011 INFO] Saving checkpoint model_step_1100.pt\n",
            "[2022-07-30 08:00:06,300 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 08:00:06,408 INFO] number of examples: 7095\n",
            "[2022-07-30 08:00:10,901 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 08:00:11,073 INFO] number of examples: 7095\n",
            "[2022-07-30 08:00:15,562 INFO] Step 1150/100000; acc:  66.57; ppl:  3.85; xent: 1.35; lr: 0.00015; 13863/22985 tok/s;    241 sec\n",
            "[2022-07-30 08:00:15,562 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 08:00:15,670 INFO] number of examples: 7095\n",
            "[2022-07-30 08:00:20,215 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 08:00:20,323 INFO] number of examples: 7095\n",
            "[2022-07-30 08:00:24,806 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 08:00:24,970 INFO] number of examples: 7095\n",
            "[2022-07-30 08:00:25,745 INFO] Step 1200/100000; acc:  68.04; ppl:  3.59; xent: 1.28; lr: 0.00016; 14425/24248 tok/s;    251 sec\n",
            "[2022-07-30 08:00:25,746 INFO] Loading dataset from data/dgs.valid.0.pt\n",
            "[2022-07-30 08:00:25,753 INFO] number of examples: 519\n",
            "[2022-07-30 08:00:25,938 INFO] Validation perplexity: 10.3595\n",
            "[2022-07-30 08:00:25,938 INFO] Validation accuracy: 55.6248\n",
            "[2022-07-30 08:00:25,938 INFO] Stalled patience: 2/3\n",
            "[2022-07-30 08:00:25,949 INFO] Saving checkpoint model_step_1200.pt\n",
            "[2022-07-30 08:00:30,165 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 08:00:30,271 INFO] number of examples: 7095\n",
            "[2022-07-30 08:00:34,769 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 08:00:34,927 INFO] number of examples: 7095\n",
            "[2022-07-30 08:00:36,515 INFO] Step 1250/100000; acc:  70.17; ppl:  3.28; xent: 1.19; lr: 0.00017; 13770/22919 tok/s;    262 sec\n",
            "[2022-07-30 08:00:39,424 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 08:00:39,538 INFO] number of examples: 7095\n",
            "[2022-07-30 08:00:44,095 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 08:00:44,205 INFO] number of examples: 7095\n",
            "[2022-07-30 08:00:46,546 INFO] Step 1300/100000; acc:  72.27; ppl:  3.01; xent: 1.10; lr: 0.00017; 14475/24307 tok/s;    272 sec\n",
            "[2022-07-30 08:00:46,546 INFO] Loading dataset from data/dgs.valid.0.pt\n",
            "[2022-07-30 08:00:46,554 INFO] number of examples: 519\n",
            "[2022-07-30 08:00:46,730 INFO] Validation perplexity: 10.4656\n",
            "[2022-07-30 08:00:46,730 INFO] Validation accuracy: 55.3194\n",
            "[2022-07-30 08:00:46,730 INFO] Stalled patience: 1/3\n",
            "[2022-07-30 08:00:46,741 INFO] Saving checkpoint model_step_1300.pt\n",
            "[2022-07-30 08:00:49,396 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 08:00:49,557 INFO] number of examples: 7095\n",
            "[2022-07-30 08:00:54,060 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 08:00:54,168 INFO] number of examples: 7095\n",
            "[2022-07-30 08:00:57,302 INFO] Step 1350/100000; acc:  74.09; ppl:  2.79; xent: 1.03; lr: 0.00018; 13754/22986 tok/s;    283 sec\n",
            "[2022-07-30 08:00:58,694 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 08:00:58,864 INFO] number of examples: 7095\n",
            "[2022-07-30 08:01:03,383 INFO] Loading dataset from data/dgs.train.0.pt\n",
            "[2022-07-30 08:01:03,490 INFO] number of examples: 7095\n",
            "[2022-07-30 08:01:07,470 INFO] Step 1400/100000; acc:  76.00; ppl:  2.59; xent: 0.95; lr: 0.00019; 14488/24184 tok/s;    293 sec\n",
            "[2022-07-30 08:01:07,470 INFO] Loading dataset from data/dgs.valid.0.pt\n",
            "[2022-07-30 08:01:07,479 INFO] number of examples: 519\n",
            "[2022-07-30 08:01:07,657 INFO] Validation perplexity: 10.481\n",
            "[2022-07-30 08:01:07,658 INFO] Validation accuracy: 55.7776\n",
            "[2022-07-30 08:01:07,658 INFO] Stalled patience: 0/3\n",
            "[2022-07-30 08:01:07,658 INFO] Training finished after stalled validations. Early Stop!\n",
            "[2022-07-30 08:01:07,658 INFO] Best model found at step 1100\n",
            "[2022-07-30 08:01:07,671 INFO] Saving checkpoint model_step_1400.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python translate.py -model model_step_1400.pt -src data/phoenix2014T.test.gloss -output pred.txt -gpu 0 -replace_unk -beam_size 4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKACL2ax-qal",
        "outputId": "d15963ac-80db-4896-dd6d-83ad1119692c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2022-07-30 08:01:17,758 INFO] Translating shard 0.\n",
            "/content/transformer-slt/onmt/translate/beam_search.py:187: UserWarning: An output with one or more elements was resized since it had shape [120], which does not match the required output shape [30, 4]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:17.)\n",
            "  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n",
            "/content/transformer-slt/onmt/translate/beam_search.py:187: UserWarning: An output with one or more elements was resized since it had shape [48], which does not match the required output shape [12, 4]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:17.)\n",
            "  torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)\n",
            "PRED AVG SCORE: -0.5446, PRED PPL: 1.7239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BLEU-1,2,3,4\n",
        "!python tools/bleu.py 1 pred.txt data/phoenix2014T.test.de\n",
        "!python tools/bleu.py 2 pred.txt data/phoenix2014T.test.de\n",
        "!python tools/bleu.py 3 pred.txt data/phoenix2014T.test.de\n",
        "!python tools/bleu.py 4 pred.txt data/phoenix2014T.test.de\n",
        "\n",
        "# ROUGE\n",
        "!python tools/rouge.py pred.txt data/phoenix2014T.test.de\n",
        "\n",
        "# METEOR\n",
        "!python tools/meteor.py pred.txt data/phoenix2014T.test.de"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyIzejxhAJ1d",
        "outputId": "050a26fe-a46a-400e-e700-5c3c88f604de"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4604190793188173\n",
            "0.342523215600003\n",
            "0.2697733069312829\n",
            "0.2228712296673685\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Traceback (most recent call last):\n",
            "  File \"tools/rouge.py\", line 806, in <module>\n",
            "    stemming=True)\n",
            "  File \"tools/rouge.py\", line 89, in __init__\n",
            "    Rouge.load_wordnet_db(ensure_compatibility)\n",
            "  File \"tools/rouge.py\", line 119, in load_wordnet_db\n",
            "    raise FileNotFoundError(\"The file '{}' does not exist\".format(filepath))\n",
            "FileNotFoundError: The file 'tools/wordnet_key_value.txt' does not exist\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "Traceback (most recent call last):\n",
            "  File \"tools/meteor.py\", line 14, in <module>\n",
            "    scores = [nltk.meteor([t.lower()], p.lower()) for t,p in zip(target, pred)]\n",
            "  File \"tools/meteor.py\", line 14, in <listcomp>\n",
            "    scores = [nltk.meteor([t.lower()], p.lower()) for t,p in zip(target, pred)]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/nltk/translate/meteor_score.py\", line 408, in meteor_score\n",
            "    for reference in references\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/nltk/translate/meteor_score.py\", line 408, in <genexpr>\n",
            "    for reference in references\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/nltk/translate/meteor_score.py\", line 327, in single_meteor_score\n",
            "    hypothesis, reference, preprocess=preprocess\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/nltk/translate/meteor_score.py\", line 34, in _generate_enums\n",
            "    f'\"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): {hypothesis}'\n",
            "TypeError: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): aber das ist ja da nicht mehr so schön aber wahrscheinlich nicht .\n",
            "\n"
          ]
        }
      ]
    }
  ]
}